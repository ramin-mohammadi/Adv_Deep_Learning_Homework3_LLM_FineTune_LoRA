{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "- Connect to a T4 GPU\n",
        "- unfortunately will manually have to create folders then drag and drop files every session\n",
        "\n",
        "Folders and the files in them\n",
        "- data (train,valid,rft.json)\n",
        "- grader\n",
        "- homework\n",
        "- requirements.txt\n",
        "- bundle.py\n",
        "- sft.zip  -> this is our trained sft model\n",
        "- rft.zip"
      ],
      "metadata": {
        "id": "0121jSn6QsEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sft.zip 'homework/sft_model/*' -d ./homework/sft_model\n",
        "!mv ./homework/sft_model/homework/sft_model/* ./homework/sft_model\n",
        "!rm -rf ./homework/sft_model/homework"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-5jh9Sr8ae-",
        "outputId": "3bc8dccc-de04-4230-b831-3f7e3cc67cd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sft.zip\n",
            "   creating: ./homework/sft_model/homework/sft_model/\n",
            "  inflating: ./homework/sft_model/homework/sft_model/vocab.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/events.out.tfevents.1744929803.e57bcc50b657.1227.0  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/training_args.bin  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/README.md  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/tokenizer_config.json  \n",
            "   creating: ./homework/sft_model/homework/sft_model/checkpoint-160/\n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/rng_state.pth  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/vocab.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/training_args.bin  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/README.md  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/tokenizer_config.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/optimizer.pt  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/special_tokens_map.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/scheduler.pt  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/adapter_config.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/merges.txt  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/tokenizer.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/adapter_model.safetensors  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/checkpoint-160/trainer_state.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/special_tokens_map.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/adapter_config.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/merges.txt  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/tokenizer.json  \n",
            "  inflating: ./homework/sft_model/homework/sft_model/adapter_model.safetensors  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip rft_360M.zip -d ./homework/rft_model\n",
        "!mv ./homework/rft_model/homework/rft_model/* ./homework/rft_model\n",
        "!rm -rf ./homework/rft_model/homework"
      ],
      "metadata": {
        "id": "S3PGRtfUURSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptLzzxdyQmBI",
        "outputId": "3a4eacbb-cf05-4f3a-dc3c-ae851ce56fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire>=0.7.0 (from -r requirements.txt (line 1))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning>=2.5.0 (from -r requirements.txt (line 2))\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.50.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.51.1)\n",
            "Collecting numpy>=2.2.1 (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Collecting peft>=0.15.0 (from -r requirements.txt (line 10))\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.7.0->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (24.2)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (4.13.1)\n",
            "Collecting pytorch-lightning (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->-r requirements.txt (line 4)) (0.30.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->-r requirements.txt (line 4)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->-r requirements.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.15.0->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (3.11.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.15.0->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.50.0->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.50.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.50.0->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.50.0->-r requirements.txt (line 4)) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.19.0)\n",
            "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=b2167196f761d9e6f5ea8cd73b73d3bac22f20bc387ca21589af6d3a729d9fc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, peft, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fire-0.7.0 lightning-2.5.1 lightning-utilities-0.14.3 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.15.2 pytorch-lightning-2.5.1 torchmetrics-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1\n",
        "!python -m homework.base_llm test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCfXVaTSjI87",
        "outputId": "49a2c52b-7bce-4f16-b73d-616021decde7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.base_llm' found in sys.modules after import of package 'homework', but prior to execution of 'homework.base_llm'; this may result in unpredictable behaviour\n",
            "tokenizer_config.json: 100% 3.76k/3.76k [00:00<00:00, 12.7MB/s]\n",
            "vocab.json: 100% 801k/801k [00:00<00:00, 3.65MB/s]\n",
            "merges.txt: 100% 466k/466k [00:00<00:00, 3.36MB/s]\n",
            "tokenizer.json: 100% 2.10M/2.10M [00:00<00:00, 15.2MB/s]\n",
            "special_tokens_map.json: 100% 655/655 [00:00<00:00, 5.65MB/s]\n",
            "config.json: 100% 846/846 [00:00<00:00, 8.03MB/s]\n",
            "2025-04-17 16:20:34.746655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744906834.985229    1225 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744906835.048586    1225 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-17 16:20:35.578758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 724M/724M [00:03<00:00, 220MB/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 902kB/s]\n",
            "testing generate function\n",
            "input The cat went up\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "output  the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs\n",
            "testing generate function\n",
            "input The dog went down\n",
            "output  the stairs and into the basement.\n",
            "\n",
            "The dog went down the stairs and into the basement.\n",
            "\n",
            "Which sentence is correct?\n",
            "[' the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs, and the cat went up the stairs', ' the stairs and into the basement.\\n\\nThe dog went down the stairs and into the basement.\\n\\nWhich sentence is correct?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2\n",
        "!python -m homework.cot test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o92ykN4jKun",
        "outputId": "7d739d9b-8273-4167-813f-1719cad74fb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.cot' found in sys.modules after import of package 'homework', but prior to execution of 'homework.cot'; this may result in unpredictable behaviour\n",
            "2025-04-17 16:21:16.372599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744906876.392905    1452 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744906876.399401    1452 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-17 16:21:16.420723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32:   0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:13<00:00,  3.40s/it]\n",
            "benchmark_result.accuracy=0.6  benchmark_result.answer_rate=0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3 -> took about 7 minutes\n",
        "!python -m homework.sft train --output_dir ./homework/sft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjIEzAPP6m-1",
        "outputId": "7cc233bc-3db7-4a87-953d-c949ec62876b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
            "tokenizer_config.json: 100% 3.76k/3.76k [00:00<00:00, 25.5MB/s]\n",
            "vocab.json: 100% 801k/801k [00:00<00:00, 1.24MB/s]\n",
            "merges.txt: 100% 466k/466k [00:00<00:00, 1.11MB/s]\n",
            "tokenizer.json: 100% 2.10M/2.10M [00:00<00:00, 2.44MB/s]\n",
            "special_tokens_map.json: 100% 655/655 [00:00<00:00, 4.31MB/s]\n",
            "config.json: 100% 846/846 [00:00<00:00, 5.53MB/s]\n",
            "2025-04-17 22:43:09.953114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744929790.211788    1227 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744929790.284069    1227 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-17 22:43:10.842221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 724M/724M [00:02<00:00, 264MB/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 960kB/s]\n",
            "trainable params: 4,341,760 || all params: 366,162,880 || trainable%: 1.1857\n",
            "/content/homework/sft.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "  0% 0/160 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "{'train_runtime': 540.2944, 'train_samples_per_second': 9.254, 'train_steps_per_second': 0.296, 'train_loss': 0.3080707788467407, 'epoch': 5.0}\n",
            "100% 160/160 [09:00<00:00,  3.38s/it]\n",
            "LLM Running on Micro Batches 32:   0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:04<00:00,  1.25s/it]\n",
            "benchmark_result.accuracy=0.71  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Zip trained sft model which is regarding files saved in ./homework/sft_model\n",
        "!zip -r sft.zip ./homework/sft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRdpuj5B_iiw",
        "outputId": "ed19d622-26f9-4000-baf9-acf711601eba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: homework/sft_model/ (stored 0%)\n",
            "  adding: homework/sft_model/vocab.json (deflated 59%)\n",
            "  adding: homework/sft_model/events.out.tfevents.1744929803.e57bcc50b657.1227.0 (deflated 60%)\n",
            "  adding: homework/sft_model/training_args.bin (deflated 52%)\n",
            "  adding: homework/sft_model/README.md (deflated 66%)\n",
            "  adding: homework/sft_model/tokenizer_config.json (deflated 84%)\n",
            "  adding: homework/sft_model/special_tokens_map.json (deflated 71%)\n",
            "  adding: homework/sft_model/adapter_config.json (deflated 55%)\n",
            "  adding: homework/sft_model/merges.txt (deflated 55%)\n",
            "  adding: homework/sft_model/tokenizer.json (deflated 82%)\n",
            "  adding: homework/sft_model/adapter_model.safetensors (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Create Augmeneted Dataset\n",
        "!python -m homework.datagen --output_json ./data/rft.json --oversample 10 --temperature 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qt_tTRd_Jau",
        "outputId": "93b34f10-08b4-405e-8728-93e9be09a2e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-18 04:27:53.589294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744950473.609656   16190 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744950473.615862   16190 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 04:27:53.636631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32: 100% 32/32 [24:50<00:00, 46.57s/it]\n",
            "Augmented train dataset size: 697\n",
            "First 5 entires of augmented dataset:\n",
            "[['Can you change 2 hour to its equivalent in min?', 120.0, np.str_('1 hour = 60 min. 2 * 60 =<answer>120</answer>')], ['What is the conversion of 2 hour to seconds?', 7200.0, np.str_('1 hour = 3600 seconds. 2 * 3600 =<answer>7200</answer>')], ['How many gram are there per 6 kg?', 6000.0, np.str_('1 gram = 1000 grams per 1 kg. 6 * 1000 =<answer>6000</answer>')], ['How much is 10 pint when converted to milliliter?', 4731.8, np.str_('1 pint = 473.18 ml. 10 * 473.18 =<answer>4731.8</answer>')], ['Convert the measurement of 6 l into cm^3.', 6000.0, np.str_('1 liter = 1000 cubic centimeters. 6 * 1000 =<answer>6000</answer>')], ['Can you change 9 metric ton to its equivalent in kg?', 9000.0, np.str_('1 metric ton = 1000 kg. 9.0 * 1000 =<answer>9000</answer>')], ['Please convert 6 mi/h into in/s.', 105.6, np.str_('1 mi/h = 17.6 in/s. 6 * 17.6 =<answer>105.6</answer>')], ['How many in are there per 8 ft?', 96.0, np.str_('1 ft = 12 in. 8 * 12 =<answer>96</answer>')], ['Express 8 liter as a quantity of milliliter.', 8000.0, np.str_('1 liter = 1000 milliliters. 8 * 1000 =<answer>8000</answer>')], ['Could you provide the value of 2 pound in ounce?', 32.0, np.str_('1 pound = 16 ounces. 2 * 16 =<answer>32</answer>')]]\n",
            "Dataset saved to ./data/rft.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Train on augmented datset\n",
        "!python -m homework.rft train --output_dir ./homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zvzCsvlJ8bZ",
        "outputId": "8393c731-360e-4c23-c331-1ba35511e19b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2025-04-18 05:58:51.969343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744955931.992311   39170 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744955932.000753   39170 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 05:58:52.024587: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "trainable params: 8,683,520 || all params: 370,504,640 || trainable%: 2.3437\n",
            "/content/homework/rft.py:85: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "  0% 0/110 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "{'train_runtime': 514.2272, 'train_samples_per_second': 6.777, 'train_steps_per_second': 0.214, 'train_loss': 0.1208169156854803, 'epoch': 5.0}\n",
            "100% 110/110 [08:34<00:00,  4.67s/it]\n",
            "LLM Running on Micro Batches 32:   0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:15<00:00,  3.98s/it]\n",
            "benchmark_result.accuracy=0.77  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.rft test ./homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qItuWTVncQaw",
        "outputId": "56117db5-19e8-44e5-b3ca-06a1b2501e32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
            "2025-04-18 05:50:12.677570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744955412.700726   36988 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744955412.707411   36988 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 05:50:12.730592: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LLM Running on Micro Batches 32:   0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:22<00:00,  5.56s/it]\n",
            "benchmark_result.accuracy=0.83  benchmark_result.answer_rate=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Zip trained rft model\n",
        "!zip -r rft.zip ./homework/rft_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3MueNUWQwr4",
        "outputId": "1812ed00-54f3-4295-c467-8219b558fe0c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: homework/rft_model/ (stored 0%)\n",
            "  adding: homework/rft_model/vocab.json (deflated 59%)\n",
            "  adding: homework/rft_model/events.out.tfevents.1744952143.7b15bdd75e30.23173.0 (deflated 62%)\n",
            "  adding: homework/rft_model/training_args.bin (deflated 52%)\n",
            "  adding: homework/rft_model/README.md (deflated 66%)\n",
            "  adding: homework/rft_model/tokenizer_config.json (deflated 84%)\n",
            "  adding: homework/rft_model/events.out.tfevents.1744952608.7b15bdd75e30.25185.0 (deflated 60%)\n",
            "  adding: homework/rft_model/special_tokens_map.json (deflated 71%)\n",
            "  adding: homework/rft_model/events.out.tfevents.1744952459.7b15bdd75e30.24545.0 (deflated 62%)\n",
            "  adding: homework/rft_model/events.out.tfevents.1744955937.7b15bdd75e30.39170.0 (deflated 60%)\n",
            "  adding: homework/rft_model/adapter_config.json (deflated 55%)\n",
            "  adding: homework/rft_model/merges.txt (deflated 55%)\n",
            "  adding: homework/rft_model/tokenizer.json (deflated 82%)\n",
            "  adding: homework/rft_model/adapter_model.safetensors (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test using local grader\n",
        "!python -m grader homework -vv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9X5Gca7i1KN",
        "outputId": "638b0185-0da5-41e9-e76b-a9b25b9913c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val grader loaded.\n",
            "\u001b[32m[DEBUG    00:00:000] \u001b[0m\u001b[32mLoading assignment\u001b[0m\n",
            "\u001b[32m[DEBUG    00:01:662] \u001b[0m\u001b[32mLoading grader\u001b[0m\n",
            "\u001b[97m[INFO     00:01:662] \u001b[0m\u001b[97mModel non-batched inference grader\u001b[0m\n",
            "2025-04-18 06:17:09.137927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744957029.159085   43835 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744957029.165921   43835 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 06:17:09.187187: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "  0% 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "100% 32/32 [00:04<00:00,  6.52it/s]\n",
            "\u001b[33m[WARNING  00:14:523] \u001b[0m\u001b[33m  - Test non-batched generate function                 [ 10 / 10  ]\u001b[0m\n",
            "\u001b[97m[INFO     00:14:524] \u001b[0m\u001b[97m --------------------------------------------------    [  10 /  10 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:14:524] \u001b[0m\u001b[97mModel batched inference grader\u001b[0m\n",
            "\u001b[33m[WARNING  00:19:454] \u001b[0m\u001b[33m  - Test batched generate function                     [ 15 / 15  ]\u001b[0m\n",
            "\u001b[97m[INFO     00:19:455] \u001b[0m\u001b[97m --------------------------------------------------    [  15 /  15 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:19:455] \u001b[0m\u001b[97mCoT Model Grader\u001b[0m\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:13<00:00,  3.35s/it]\n",
            "\u001b[32m[DEBUG    00:34:879] \u001b[0m\u001b[32m0.6\u001b[0m\n",
            "\u001b[33m[WARNING  00:34:912] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 25 / 25  ]\u001b[0m\n",
            "\u001b[97m[INFO     00:34:912] \u001b[0m\u001b[97m --------------------------------------------------    [  25 /  25 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:34:913] \u001b[0m\u001b[97mSFT Model Grader\u001b[0m\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:04<00:00,  1.13s/it]\n",
            "\u001b[32m[DEBUG    00:41:757] \u001b[0m\u001b[32m0.71\u001b[0m\n",
            "\u001b[33m[WARNING  00:41:820] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 25 / 25  ]\u001b[0m\n",
            "\u001b[97m[INFO     00:41:820] \u001b[0m\u001b[97m --------------------------------------------------    [  25 /  25 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:41:821] \u001b[0m\u001b[97mRFT Model Grader\u001b[0m\n",
            "LLM Running on Micro Batches 32: 100% 4/4 [00:15<00:00,  3.90s/it]\n",
            "\u001b[32m[DEBUG    00:59:275] \u001b[0m\u001b[32m0.77\u001b[0m\n",
            "\u001b[33m[WARNING  00:59:289] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 28 / 25  ]\u001b[0m\n",
            "\u001b[97m[INFO     00:59:289] \u001b[0m\u001b[97m --------------------------------------------------    [  28 /  25 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:59:289] \u001b[0m\u001b[97mTotal                                                    103 / 100\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before bundling, remove all checkpoint folders to reduce zipped file size\n",
        "!rm -r ./homework/sft_model/checkpoint*\n",
        "!rm -r ./homework/rft_model/checkpoint*"
      ],
      "metadata": {
        "id": "rA9PnKvLZC--"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bundle\n",
        "!python bundle.py homework rm59549"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ4GCqfKZVcL",
        "outputId": "d0896265-e910-45d3-ed29-32557a13da0e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cot.py\n",
            "sft.py\n",
            "__init__.py\n",
            "rft_model\n",
            "base_llm.py\n",
            "datagen.py\n",
            "data.py\n",
            "sft_model\n",
            "rft.py\n",
            "rft_model/vocab.json\n",
            "rft_model/events.out.tfevents.1744952143.7b15bdd75e30.23173.0\n",
            "rft_model/training_args.bin\n",
            "rft_model/README.md\n",
            "rft_model/tokenizer_config.json\n",
            "rft_model/events.out.tfevents.1744952608.7b15bdd75e30.25185.0\n",
            "rft_model/special_tokens_map.json\n",
            "rft_model/events.out.tfevents.1744952459.7b15bdd75e30.24545.0\n",
            "rft_model/events.out.tfevents.1744955937.7b15bdd75e30.39170.0\n",
            "rft_model/adapter_config.json\n",
            "rft_model/merges.txt\n",
            "rft_model/tokenizer.json\n",
            "rft_model/adapter_model.safetensors\n",
            "sft_model/vocab.json\n",
            "sft_model/events.out.tfevents.1744929803.e57bcc50b657.1227.0\n",
            "sft_model/training_args.bin\n",
            "sft_model/README.md\n",
            "sft_model/tokenizer_config.json\n",
            "sft_model/special_tokens_map.json\n",
            "sft_model/adapter_config.json\n",
            "sft_model/merges.txt\n",
            "sft_model/tokenizer.json\n",
            "sft_model/adapter_model.safetensors\n",
            "Warning: The created zip file is larger than expected!\n",
            "Submission created: /content/rm59549.zip 48.27 MB\n"
          ]
        }
      ]
    }
  ]
}